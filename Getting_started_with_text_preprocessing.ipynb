{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data Preprocessing\n",
    "\n",
    "In any machine learning task, cleaning or preprocessing the data is as important as model building if not more. And when it comes to unstructured data like text, this process is even more important.\n",
    "\n",
    "Objective of this notebook is to understand the various text preprocessing steps with code examples.\n",
    "\n",
    "Some of the common text preprocessing / cleaning steps are:\n",
    "\n",
    "* Lower casing\n",
    "* Removal of Punctuations\n",
    "* Removal of Stopwords\n",
    "* Removal of Frequent words\n",
    "* Removal of Rare words\n",
    "* Stemming\n",
    "* Lemmatization\n",
    "* Removal of emojis\n",
    "* Removal of URLs\n",
    "\n",
    "\n",
    "So these are the different types of text preprocessing steps which we can do on text data. But we need not do all of these all the times. We need to carefully choose the preprocessing steps based on our use case since that also play an important role.\n",
    "\n",
    "For example, in sentiment analysis use case, we need not remove the emojis as it will convey some important information about the sentiment. Similarly we need to decide based on our use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.0.6-cp38-cp38-manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.0 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /home/praveen/anaconda3/lib/python3.8/site-packages (from spacy) (49.2.0.post20200714)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp38-cp38-manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.5.2-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42 kB 189 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp38-cp38-manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.8 MB 570 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in /home/praveen/anaconda3/lib/python3.8/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /home/praveen/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.2)\n",
      "Collecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.4-cp38-cp38-manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.3 MB 147 kB/s eta 0:00:01    |‚ñà‚ñç                              | 512 kB 6.9 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp38-cp38-manylinux2014_x86_64.whl (458 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 458 kB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /home/praveen/anaconda3/lib/python3.8/site-packages (from spacy) (2.24.0)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "  Downloading thinc-8.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 628 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp38-cp38-manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 130 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /home/praveen/anaconda3/lib/python3.8/site-packages (from spacy) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /home/praveen/anaconda3/lib/python3.8/site-packages (from spacy) (20.4)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
      "  Downloading spacy_legacy-3.0.6-py2.py3-none-any.whl (12 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp38-cp38-manylinux2014_x86_64.whl (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.3\n",
      "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /home/praveen/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 113 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /home/praveen/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/praveen/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/praveen/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/praveen/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/praveen/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/praveen/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /home/praveen/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=7a4dea3dacd4bdcce8fe6e64e960c7cdd07229a53025eaadc7a7219edcfa2666\n",
      "  Stored in directory: /home/praveen/.cache/pip/wheels/11/73/9a/f91ac1f1816436b16423617c5be5db048697ff152a9c4346f2\n",
      "Successfully built smart-open\n",
      "Installing collected packages: typer, cymem, smart-open, pathy, blis, pydantic, wasabi, catalogue, srsly, murmurhash, preshed, thinc, spacy-legacy, spacy\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.4 cymem-2.0.5 murmurhash-1.0.5 pathy-0.5.2 preshed-3.0.5 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.6 srsly-2.4.1 thinc-8.0.6 typer-0.3.2 wasabi-0.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('text.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 What's that egg website people talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BXrVfeIXxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 We can assist you. We recommend updating to iOS 11.1.1 if you haven't had the chance to do so. You can also DM us with the following link for futher support. https://t.co/GDrqU22YpT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 Thats better than having an unstable connection that drops every 5-20 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica is probably one of the best airlines I've ever experienced.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                            text\n",
       "0                                                                                                                                              @161252 What's that egg website people talk about\n",
       "1                                                                                                                                         Why!ü§∑üèª‚Äç‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BXrVfeIXxq\n",
       "2  @693975 We can assist you. We recommend updating to iOS 11.1.1 if you haven't had the chance to do so. You can also DM us with the following link for futher support. https://t.co/GDrqU22YpT\n",
       "3                                                                                                     @331912 @115955 Thats better than having an unstable connection that drops every 5-20 mins\n",
       "4                                                                                                                     @VirginAmerica is probably one of the best airlines I've ever experienced."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string = data['text'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why!ü§∑üèª\\u200d‚ôÄÔ∏è #iOS11 @AppleSupport https://t.co/BXrVfeIXxq'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Casing\n",
    "Lower casing is a common text preprocessing technique. The idea is to convert the input text into same casing format so that 'text', 'Text' and 'TEXT' are treated the same way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why!ü§∑üèª\\u200d‚ôÄÔ∏è #ios11 @applesupport https://t.co/bxrvfeixxq'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@161252 what's that egg website people talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bxrvfeixxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@693975 we can assist you. we recommend updating to ios 11.1.1 if you haven't had the chance to do so. you can also dm us with the following link for futher support. https://t.co/gdrqu22ypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@331912 @115955 thats better than having an unstable connection that drops every 5-20 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@virginamerica is probably one of the best airlines i've ever experienced.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                            text\n",
       "0                                                                                                                                              @161252 what's that egg website people talk about\n",
       "1                                                                                                                                         why!ü§∑üèª‚Äç‚ôÄÔ∏è #ios11 @applesupport https://t.co/bxrvfeixxq\n",
       "2  @693975 we can assist you. we recommend updating to ios 11.1.1 if you haven't had the chance to do so. you can also dm us with the following link for futher support. https://t.co/gdrqu22ypt\n",
       "3                                                                                                     @331912 @115955 thats better than having an unstable connection that drops every 5-20 mins\n",
       "4                                                                                                                     @virginamerica is probably one of the best airlines i've ever experienced."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Punctuations\n",
    "\n",
    "One another common text preprocessing technique is to remove the punctuations from the text data. This is again a text standardization process that will help to treat 'hurray' and 'hurray!' in the same way.\n",
    "\n",
    "We also need to carefully choose the list of punctuations to exclude depending on the use case. For example, the string.punctuation in python contains the following punctuation symbols !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n",
    "\n",
    "We can add or remove more punctuations as per our need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puncts = string.punctuation\n",
    "puncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Hey! It\\'s me. What\\'s up?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey! It's me. What's up?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey Its me Whats up'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[^\\d\\w\\s]\", \"\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whyü§∑üèª\\u200d‚ôÄÔ∏è iOS11 AppleSupport httpstcoBXrVfeIXxq'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]\", \"\", sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why!ü§∑üèª‚Äç‚ôÄÔ∏è\n",
      "iOS11\n",
      "AppleSupport\n",
      "https://t.co/BXrVfeIXxq\n"
     ]
    }
   ],
   "source": [
    "for s in sample_string.split():\n",
    "    print(s.strip(puncts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    \n",
    "    res = []\n",
    "    for t in text.split():\n",
    "        if t.lower().startswith('http'):\n",
    "            res.append(t)\n",
    "        else:\n",
    "            res.append(t.translate(str.maketrans('', '', puncts)))\n",
    "        \n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whyü§∑üèª\\u200d‚ôÄÔ∏è iOS11 AppleSupport https://t.co/BXrVfeIXxq'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuation(sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161252 whats that egg website people talk about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whyü§∑üèª‚Äç‚ôÄÔ∏è ios11 applesupport https://t.co/bxrvfeixxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693975 we can assist you we recommend updating to ios 1111 if you havent had the chance to do so you can also dm us with the following link for futher support https://t.co/gdrqu22ypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331912 115955 thats better than having an unstable connection that drops every 520 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica is probably one of the best airlines ive ever experienced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                     text\n",
       "0                                                                                                                                         161252 whats that egg website people talk about\n",
       "1                                                                                                                                     whyü§∑üèª‚Äç‚ôÄÔ∏è ios11 applesupport https://t.co/bxrvfeixxq\n",
       "2  693975 we can assist you we recommend updating to ios 1111 if you havent had the chance to do so you can also dm us with the following link for futher support https://t.co/gdrqu22ypt\n",
       "3                                                                                                 331912 115955 thats better than having an unstable connection that drops every 520 mins\n",
       "4                                                                                                                 virginamerica is probably one of the best airlines ive ever experienced"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of stopwords\n",
    "Stopwords are commonly occuring words in a language like 'the', 'a' and so on. They can be removed from the text most of the times, as they don't provide valuable information for downstream analysis. In cases like Part of Speech tagging, we should not remove them as provide very valuable information about the POS.\n",
    "\n",
    "These stopword lists are already compiled for different languages and we can safely use them. For example, the stopword list for english language from the nltk package can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/praveen/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stw = nltk.corpus.stopwords.words('english')\n",
    "print(stw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for w in text.split():\n",
    "        if w.lower() not in stw:\n",
    "            res.append(w)\n",
    "            \n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161252 whats egg website people talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whyü§∑üèª‚Äç‚ôÄÔ∏è ios11 applesupport https://t.co/bxrvfeixxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693975 assist recommend updating ios 1111 havent chance also dm us following link futher support https://t.co/gdrqu22ypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331912 115955 thats better unstable connection drops every 520 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica probably one best airlines ive ever experienced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       text\n",
       "0                                                                                      161252 whats egg website people talk\n",
       "1                                                                       whyü§∑üèª‚Äç‚ôÄÔ∏è ios11 applesupport https://t.co/bxrvfeixxq\n",
       "2  693975 assist recommend updating ios 1111 havent chance also dm us following link futher support https://t.co/gdrqu22ypt\n",
       "3                                                       331912 115955 thats better unstable connection drops every 520 mins\n",
       "4                                                             virginamerica probably one best airlines ive ever experienced"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Frequent words\n",
    "In the previos preprocessing step, we removed the stopwords based on language information. But say, if we have a domain specific corpus, we might also have some frequent words which are of not so much importance to us.\n",
    "\n",
    "So this step is to remove the frequent words in the given corpus. If we use something like tfidf, this is automatically taken care of.\n",
    "\n",
    "Let us get the most common words adn then remove them in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in data['text'].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['us', 'please', 'dm', 'help', 'hi', 'thanks', 'get', 'sorry', 'like', 'send']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent = [c[0] for c in cnt.most_common(10)]\n",
    "\n",
    "most_frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_frequent_words(text):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for w in text.split():\n",
    "        if w.lower() not in most_frequent:\n",
    "            res.append(w)\n",
    "            \n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(remove_frequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161252 whats egg website people talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whyü§∑üèª‚Äç‚ôÄÔ∏è ios11 applesupport https://t.co/bxrvfeixxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693975 assist recommend updating ios 1111 havent chance also following link futher support https://t.co/gdrqu22ypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331912 115955 thats better unstable connection drops every 520 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica probably one best airlines ive ever experienced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text\n",
       "0                                                                                161252 whats egg website people talk\n",
       "1                                                                 whyü§∑üèª‚Äç‚ôÄÔ∏è ios11 applesupport https://t.co/bxrvfeixxq\n",
       "2  693975 assist recommend updating ios 1111 havent chance also following link futher support https://t.co/gdrqu22ypt\n",
       "3                                                 331912 115955 thats better unstable connection drops every 520 mins\n",
       "4                                                       virginamerica probably one best airlines ive ever experienced"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Rare words\n",
    "This is very similar to previous preprocessing step but we will remove the rare words from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_words = set([w[0] for w in cnt.most_common() if w[1] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'621596',\n",
       " 'erl√§utern',\n",
       " '299399',\n",
       " 'https://t.co/eanzc2r8hr',\n",
       " 'telefon',\n",
       " 'futurista',\n",
       " '373657',\n",
       " '639167',\n",
       " 'graciasüòä',\n",
       " 'validity',\n",
       " 'unreal',\n",
       " 'https://t.co/dnojkdg8yg',\n",
       " 'marathon',\n",
       " '116130',\n",
       " '160984',\n",
       " '761300',\n",
       " 'https://t.co/fnpx9tlyr5.',\n",
       " '835',\n",
       " 'year‚Äôs',\n",
       " 'canon',\n",
       " 'unsure',\n",
       " '08056467521',\n",
       " '122783',\n",
       " '478414',\n",
       " 'hu',\n",
       " '147496',\n",
       " 'darn',\n",
       " 'jake',\n",
       " '260566',\n",
       " 'infuriating',\n",
       " 'https://t.co/0tekt3bdrz',\n",
       " 'elegante',\n",
       " 'llegaba',\n",
       " 'patton',\n",
       " 'saludos',\n",
       " 'uo',\n",
       " '206',\n",
       " 'lincoln',\n",
       " 'businessmen',\n",
       " 'freeezes',\n",
       " 'mendatory',\n",
       " '509636',\n",
       " 'üëå',\n",
       " 'nigeria',\n",
       " 'samaila',\n",
       " 'contentchannels',\n",
       " '418866',\n",
       " '0652',\n",
       " 'hampers',\n",
       " 'hotline',\n",
       " 'devon',\n",
       " 'shuttering',\n",
       " '308013',\n",
       " 'alerted',\n",
       " '388013',\n",
       " 'https://t.co/l3uq3fh3rf',\n",
       " 'leihfrist',\n",
       " 'tromp√©',\n",
       " '634681',\n",
       " 'choisir',\n",
       " '217164',\n",
       " 'https://t.co/8d3rjazbir',\n",
       " '√∫ltimos',\n",
       " '591005',\n",
       " 'senioritis',\n",
       " 'sourced',\n",
       " '778204',\n",
       " '811371',\n",
       " 'partag√©',\n",
       " 'replyingwill',\n",
       " 'forks',\n",
       " 'larry',\n",
       " '„Åì„Å°„Çâ„Åì„Åù„ÄÅ‰∏ÅÂØß„Å™„É™„Éó„É©„Ç§„Çí„ÅÑ„Åü„Å†„Åç„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇ‰ªäÂæå„ÇÇ„Åî‰∏çÊòéÁÇπ„Å™„Å©„Åå„Åî„Åñ„ÅÑ„Åæ„Åó„Åü„Çâ„ÅäÁü•„Çâ„Åõ„Åè„Å†„Åï„ÅÑ„ÄÇmh',\n",
       " '149228',\n",
       " '762519',\n",
       " '332914',\n",
       " 'accidental',\n",
       " 'consistent',\n",
       " 'nav',\n",
       " '739760',\n",
       " '413204',\n",
       " 'rainingwhy',\n",
       " 'nadie',\n",
       " 'stars',\n",
       " 'rechtzeitig',\n",
       " '431141',\n",
       " 'pushing',\n",
       " '137659',\n",
       " 'cooler',\n",
       " '63437',\n",
       " 'https://t.co/7jcyxicqse.',\n",
       " 'https://t.co/q0x5pih7bm.',\n",
       " 'ü§¶üèΩ\\u200d‚ôÄÔ∏è',\n",
       " 'liz',\n",
       " 'rhyl',\n",
       " 'suvidha',\n",
       " 'barring',\n",
       " 'https://t.co/0sckhvtkyo',\n",
       " 'stranded',\n",
       " 'marksandspencer‚Äôs',\n",
       " 'üëê',\n",
       " '‚òëÔ∏è',\n",
       " 'reclamaci√≥n',\n",
       " 'tengo',\n",
       " 'txts',\n",
       " '265045',\n",
       " '443265',\n",
       " '435556',\n",
       " 'ten',\n",
       " 'practically',\n",
       " 'ooor',\n",
       " 'sho',\n",
       " '121081',\n",
       " 'anywayy',\n",
       " 'https://t.co/qebwb2ot4j',\n",
       " 'greggs',\n",
       " 'dna',\n",
       " 'honour',\n",
       " 'sch√∂nen',\n",
       " 'https://t.co/g4kvjdoghx',\n",
       " '756041',\n",
       " 'recipients',\n",
       " 'https://t.co/ndpy8pgiqs',\n",
       " '75574',\n",
       " 'timetable',\n",
       " '100mbs',\n",
       " '342180',\n",
       " 'master',\n",
       " 'empresa',\n",
       " 'raha',\n",
       " 'jallonge',\n",
       " 'pr√©lev√©',\n",
       " 'kidnap',\n",
       " 'ross',\n",
       " 'spec',\n",
       " 'hotspots',\n",
       " 'stocks',\n",
       " '552927',\n",
       " 'shelf',\n",
       " 'tolls',\n",
       " 'hungryampdispleased',\n",
       " 'maintain',\n",
       " 'pagedid',\n",
       " '243814',\n",
       " 'intro',\n",
       " '186588',\n",
       " '55824',\n",
       " 'appupdates',\n",
       " 'newark',\n",
       " 'behaves',\n",
       " '170068',\n",
       " 'dl7692',\n",
       " 'https://t.co/m4hwsbghvz',\n",
       " '327972',\n",
       " 'analyses',\n",
       " 'flyers',\n",
       " 'hits',\n",
       " 'https://t.co/ld25ql7esc',\n",
       " 'https://t.co/yqihbgrnqi,',\n",
       " 'somewhat',\n",
       " '230312',\n",
       " '433230',\n",
       " '311337',\n",
       " '408193',\n",
       " '61702',\n",
       " 'engineering',\n",
       " 'ussd',\n",
       " 'jase',\n",
       " 'invitations',\n",
       " '531160',\n",
       " 'dasher',\n",
       " 'thrown',\n",
       " 'bham',\n",
       " '335461',\n",
       " 'grabbed',\n",
       " 'https://t.co/k4m4rau9gq.',\n",
       " '115754',\n",
       " 'delhi',\n",
       " 'aus',\n",
       " 'ten√≠amos',\n",
       " '414540',\n",
       " '473126',\n",
       " '221415',\n",
       " '388498',\n",
       " '236411',\n",
       " 'flt',\n",
       " '414495',\n",
       " '333046',\n",
       " 'atendimento',\n",
       " 'fixit',\n",
       " '323183',\n",
       " 'tested',\n",
       " '341611',\n",
       " 'ths',\n",
       " '23gu',\n",
       " 'spice',\n",
       " 'https://t.co/rdijwyxgke',\n",
       " 'https://t.co/ii34fya4hc.',\n",
       " 'flint',\n",
       " '743457',\n",
       " 'productivity',\n",
       " 'hired',\n",
       " 'increasing',\n",
       " '504335',\n",
       " 'freak',\n",
       " '149396',\n",
       " 'snoozeyoulose',\n",
       " 'featuring',\n",
       " '410286',\n",
       " 'displaced',\n",
       " 'posible',\n",
       " 'batter',\n",
       " '794934',\n",
       " '753130',\n",
       " 'freu',\n",
       " '573528',\n",
       " '„Éó„É©„Ç§„É†ÁâπÂÖ∏„ÅØ‰ªñ„Å´„ÇÇÊßò„ÄÖ„Åî„Åñ„ÅÑ„Åæ„Åô„ÅÆ„Åß„ÄÅ„Çà„Çç„Åó„Åè„Åë„Çå„Å∞„ÄÅ„ÅîÊ¥ªÁî®„Åè„Å†„Åï„ÅÑ„Åæ„Åõ„ÄÇ',\n",
       " '469768',\n",
       " 'tr√®s',\n",
       " 'prend',\n",
       " 'wake',\n",
       " '606297',\n",
       " 'kiosk',\n",
       " 'communicate',\n",
       " 'annual',\n",
       " '360276',\n",
       " 'upsized',\n",
       " 'stillcrying',\n",
       " '280467',\n",
       " 'https://t.co/dx8jfdnmbk',\n",
       " '822573',\n",
       " 'pakistan',\n",
       " 'pti',\n",
       " 'wimbledon',\n",
       " 'l√©tat',\n",
       " 'premi√®re',\n",
       " '688293',\n",
       " '600',\n",
       " 'tomara',\n",
       " 'mech',\n",
       " 'affecting',\n",
       " '368993',\n",
       " 'becoming',\n",
       " 'pleas',\n",
       " 'servidores',\n",
       " 'tilehurst',\n",
       " 'bucatini',\n",
       " '¬£‚Ç¨',\n",
       " 'drivethru',\n",
       " '547236',\n",
       " '275827',\n",
       " 'daystalked',\n",
       " '14th',\n",
       " 'ranch',\n",
       " 'seperate',\n",
       " 'carlisle',\n",
       " '158848',\n",
       " 'painfully',\n",
       " 'jfc',\n",
       " 'yesterday‚Äôs',\n",
       " '583197',\n",
       " 'debugged',\n",
       " 'fomo',\n",
       " 'wolstanton',\n",
       " 'jet',\n",
       " '157047',\n",
       " '206674',\n",
       " 'walkers',\n",
       " '357174',\n",
       " 'asksalesforce',\n",
       " 'bir',\n",
       " 'causedwe',\n",
       " '412360',\n",
       " '398315',\n",
       " '285',\n",
       " 'licenses',\n",
       " 'bengaluru',\n",
       " 'üò≠üôÉ',\n",
       " 'takeresponsibility',\n",
       " 'twenty',\n",
       " 'elegir',\n",
       " 'bidders',\n",
       " 'brothers',\n",
       " '18179',\n",
       " 'betsy',\n",
       " 'https://t.co/hyyafljojg',\n",
       " 'grandson‚Äôs',\n",
       " 'recib√≠',\n",
       " '137487',\n",
       " '419591',\n",
       " '395594',\n",
       " 'adventcalendar',\n",
       " 'third',\n",
       " '432575',\n",
       " 'chuckie',\n",
       " 'noche',\n",
       " '628738',\n",
       " 'episodeyour',\n",
       " 'üëéüèºüëéüèºfour',\n",
       " 'managers',\n",
       " 'adm',\n",
       " 'trolley',\n",
       " 'alors',\n",
       " '265322',\n",
       " 'appearance',\n",
       " 'alarm',\n",
       " '126060',\n",
       " 'evacuated',\n",
       " 'encomenda',\n",
       " 'drugs',\n",
       " '390533',\n",
       " 'kamalesh',\n",
       " 'retardjai',\n",
       " 'phillian',\n",
       " 'satej',\n",
       " 'curtindo',\n",
       " 'https://t.co/oyjfh1it8n',\n",
       " '33642',\n",
       " 'plasticocean',\n",
       " '235532',\n",
       " 'url',\n",
       " 'kresha',\n",
       " '2hr',\n",
       " 'promotional',\n",
       " 'rocket',\n",
       " '493457',\n",
       " 'trucks',\n",
       " '332842',\n",
       " '822579',\n",
       " 'https://t.co/ptutfq96jo',\n",
       " '690305',\n",
       " 'lcdksz',\n",
       " '785051',\n",
       " 'wen',\n",
       " 'hmmn',\n",
       " '315347',\n",
       " '513027',\n",
       " '690663',\n",
       " 'macbooks',\n",
       " 'chances',\n",
       " '579610',\n",
       " '620193',\n",
       " '372311',\n",
       " 'ÿ¥Ÿäÿ°',\n",
       " 'https://t.co/l67vyzb8bv',\n",
       " '325123',\n",
       " 'ago‚Ä¶',\n",
       " 'https://t.co/dl34v8njsn',\n",
       " 'jamacha',\n",
       " 'prescot',\n",
       " 'hillary',\n",
       " 'motiva',\n",
       " 'inconvenientes',\n",
       " 'frl',\n",
       " 'theft',\n",
       " 'exceptionally',\n",
       " '682467',\n",
       " 'jf',\n",
       " '201438',\n",
       " '443015',\n",
       " 'survived',\n",
       " '595890',\n",
       " 'charlesopacki',\n",
       " 'jessica',\n",
       " 'reparto',\n",
       " 'https://t.co/watnmgs37z',\n",
       " 'c6180',\n",
       " '212114',\n",
       " 'visiting',\n",
       " 'survey',\n",
       " '790688',\n",
       " '13030',\n",
       " '5370',\n",
       " '‚Äútry',\n",
       " 'remind',\n",
       " '308263',\n",
       " '384898',\n",
       " 'grand',\n",
       " 'warehouses',\n",
       " 'responsible',\n",
       " '633657',\n",
       " 'cancellingi',\n",
       " 'bollard',\n",
       " 'https://t.co/96rce5zffk',\n",
       " 'climate',\n",
       " 'ags',\n",
       " 'outtakes',\n",
       " 'whiteboard',\n",
       " '792202',\n",
       " 'weihnachtsb√§ckerei',\n",
       " 'worküò¢the',\n",
       " 'https://t.co/fonwc74z3e',\n",
       " 'dayseach',\n",
       " '291',\n",
       " '207623',\n",
       " '759703',\n",
       " 'nov25',\n",
       " '165535',\n",
       " 'mix',\n",
       " 'stephaniegarza',\n",
       " 'cumplido',\n",
       " 'fulla',\n",
       " 'g6',\n",
       " '783797',\n",
       " 'dayton',\n",
       " '¬¥ÔæÅÔæóÔΩØ',\n",
       " 'mcflurries',\n",
       " '5185',\n",
       " 'sortit',\n",
       " 'wheels',\n",
       " 'https://t.co/wdi2r9tcwp',\n",
       " '08157803688',\n",
       " 'obtener',\n",
       " 'erstmal',\n",
       " 'üòîyou',\n",
       " '629458',\n",
       " 'nonveggie',\n",
       " 'jorgeg',\n",
       " 'mosaic',\n",
       " 'stephaniea',\n",
       " 'iphone6',\n",
       " 'threaten',\n",
       " 'midland',\n",
       " 'ottawa',\n",
       " 'https://t.co/7i8wpdxcyy',\n",
       " '308573',\n",
       " '3¬™',\n",
       " '100s',\n",
       " 'palace',\n",
       " 'fait',\n",
       " '402286',\n",
       " '113',\n",
       " 'sollte',\n",
       " 'https://t.co/lfthvpgpvq.',\n",
       " 'troubleshoot',\n",
       " '425131',\n",
       " 'ctr',\n",
       " '106244',\n",
       " '304206',\n",
       " 'riverside',\n",
       " 'puccini',\n",
       " '164796',\n",
       " 'responds',\n",
       " 'roosevelt',\n",
       " 'marshall',\n",
       " '687774',\n",
       " '486481',\n",
       " 'exhausted',\n",
       " 'symbol',\n",
       " 'doc',\n",
       " 'https',\n",
       " 'tenders',\n",
       " '¬£45',\n",
       " 'beholder',\n",
       " 'whyamipayingsomuch',\n",
       " '341095',\n",
       " 'haneda',\n",
       " 'pradnya',\n",
       " 'calculator',\n",
       " 'üëçüèªüëçüèª',\n",
       " '145910',\n",
       " 'common',\n",
       " '15min',\n",
       " '762342',\n",
       " 'farooqplease',\n",
       " '257469',\n",
       " '167',\n",
       " '554910',\n",
       " 'https://t.co/bnbsknjcvd',\n",
       " '363816',\n",
       " '783535',\n",
       " 'ineptitude',\n",
       " '299938',\n",
       " 'worstcustomerservice',\n",
       " '814299',\n",
       " 'https://t.co/ocl9agcaqw',\n",
       " '731073',\n",
       " 'blackheath',\n",
       " 'bezos',\n",
       " '030000',\n",
       " '128818',\n",
       " 'szechuansauce',\n",
       " 'unstable',\n",
       " 'superman',\n",
       " 'sloeginmincetarts',\n",
       " '531980',\n",
       " 'emilina',\n",
       " 'authorization',\n",
       " 'medicines',\n",
       " 'welcomeki',\n",
       " 'donna',\n",
       " 'pmts',\n",
       " 'luka',\n",
       " 'bi',\n",
       " 'apples',\n",
       " 'curation',\n",
       " 'theyi',\n",
       " 'mature',\n",
       " '210712',\n",
       " 'nwdbpn',\n",
       " '146946',\n",
       " 'pippa',\n",
       " 'wizardry',\n",
       " 'novedad',\n",
       " 'chunky',\n",
       " '139211',\n",
       " 'apple‚Äôs',\n",
       " 'https://t.co/iesxt5cvhc',\n",
       " '523635',\n",
       " '377976',\n",
       " '„ÅîÂøÉÈÖç„Çí„Åä„Åã„Åë„Åó„Å¶„Åä„Çä„Åæ„Åô„ÄÇ„É°„Éº„É´‰æø„ÅÆÂ†¥Âêà„ÅØ„Éù„Çπ„Éà„Å´ÊäïÂáΩ„Åó„Å¶ÈÖçÈÅîÂÆå‰∫Ü„Å®„Å™„Çä„Åæ„Åô„ÄÇ„Éù„Çπ„Éà„Çí„ÅîÁ¢∫Ë™ç„ÅÑ„Åü„Å†„ÅÑ„Å¶„ÇÇÂïèÈ°å„ÅåËß£Ê±∫„Åó„Å™„ÅÑÂ†¥Âêà„ÅØ„ÄÅ„Ç´„Çπ„Çø„Éû„Éº„Çµ„Éº„Éì„Çπ„Åæ„Åß„ÅäÂïè„ÅÑÂêà„Çè„Åõ„Åè„Å†„Åï„ÅÑ„ÄÇhttpstcoj6yeizo6qc',\n",
       " 'https://t.co/egkoy6bcne',\n",
       " '822591',\n",
       " 'aztechhelp',\n",
       " '501407',\n",
       " 'mlb',\n",
       " '598542',\n",
       " 'independence',\n",
       " '156391',\n",
       " 'https://t.co/nts11vm3ob',\n",
       " 'https://t.co/gaheulv2qw',\n",
       " '492665',\n",
       " 'https://t.co/zt1jpakjch',\n",
       " '395147',\n",
       " 'https://t.co/gzn4oexlaf',\n",
       " 'voil√†',\n",
       " 'studentsparents',\n",
       " '181513',\n",
       " 'pia',\n",
       " '530488',\n",
       " '144969',\n",
       " 'patna',\n",
       " 'lividcn',\n",
       " '354804',\n",
       " 'https://t.co/8rz7qpj8n5',\n",
       " 'belgian',\n",
       " '761841',\n",
       " 'kills',\n",
       " '400625',\n",
       " '796942',\n",
       " 'var',\n",
       " 'crooks',\n",
       " '550574',\n",
       " 'probs',\n",
       " 'unsuccessful',\n",
       " '113959',\n",
       " 'schauen',\n",
       " 'compliance',\n",
       " 'wnt',\n",
       " '355236',\n",
       " '743209',\n",
       " 'externo',\n",
       " 'yesterdays',\n",
       " 'memmermight',\n",
       " 'intelligence',\n",
       " 'ubersuv',\n",
       " 'notificaci√≥n',\n",
       " '85',\n",
       " 'edrick',\n",
       " '359557',\n",
       " '3013',\n",
       " '409643',\n",
       " 'quotes',\n",
       " 'facility',\n",
       " 'https://t.co/ohhrqzcjzq',\n",
       " '‚ù§üêÆ',\n",
       " 'salad‚Äù',\n",
       " 'undeliverable',\n",
       " 'paint3d',\n",
       " 'welfareüôÇ',\n",
       " 'dns',\n",
       " 'lying',\n",
       " 'fridges',\n",
       " 'saffiche',\n",
       " '820243',\n",
       " 'https://t.co/8facgiuepo',\n",
       " 'replying',\n",
       " 'https://t.co/z0th7bknl5.',\n",
       " 'flipkart',\n",
       " '57686s',\n",
       " 'missouri',\n",
       " 'multiyear',\n",
       " 'turkey',\n",
       " 'croisons',\n",
       " 'üî•üî•üî•üî•üî•',\n",
       " 'merchants',\n",
       " 'businessfail',\n",
       " 'boat',\n",
       " 'paket',\n",
       " 'mcds',\n",
       " '567934',\n",
       " '571394',\n",
       " 'tripfrom',\n",
       " 'https://t.co/m0oqwgle4j',\n",
       " 'monitor',\n",
       " '117160',\n",
       " 'futures',\n",
       " '144258',\n",
       " 'latte',\n",
       " '534863',\n",
       " 'instore',\n",
       " 'teraflops',\n",
       " 'casa',\n",
       " 'inadequately',\n",
       " 'shoud',\n",
       " '204325',\n",
       " '406661',\n",
       " '127972',\n",
       " 'trop',\n",
       " '640399',\n",
       " '118894',\n",
       " 'offrir',\n",
       " '285695',\n",
       " '613498',\n",
       " 'msn',\n",
       " '361077',\n",
       " '532914',\n",
       " '199859',\n",
       " 'turismo',\n",
       " 'politics',\n",
       " '162367',\n",
       " 'herehttpstcoc6ku6z0hrd',\n",
       " '219429',\n",
       " '124820',\n",
       " 'congratulations',\n",
       " '447537',\n",
       " 'https://t.co/yothhdqdhe',\n",
       " 'https://t.co/hxjy5gdewa',\n",
       " 'nowthanks',\n",
       " 'https://t.co/mpxh4vwtn1',\n",
       " 'cableamp',\n",
       " '666070',\n",
       " 'wkd',\n",
       " 'wenzao',\n",
       " '520',\n",
       " '735515',\n",
       " '306778',\n",
       " '127588',\n",
       " '8222',\n",
       " 'hampton',\n",
       " 'amazon„Éó„É©„Ç§„É†„ÅØ„ÄÅÂàùÂÖ•‰ºöÊôÇ„Å´1ÔΩπÊúà„ÅÆÁÑ°Êñô‰ΩìÈ®ìÊúüÈñì„Åå„ÅÇ„Çä„ÄÅ„Åù„Çå‰ª•Èôç„ÅØ„ÄÅÂπ¥Èñì„Éó„É©„É≥3900ÂÜÜ„Åæ„Åü„ÅØÊúàÈñì„Éó„É©„É≥400ÂÜÜ„Åß„ÅîÂà©Áî®„ÅÑ„Åü„Å†„Åë„Åæ„Åô„ÄÇ„Çà„Çç„Åó„Åë„Çå„Å∞„ÄÅË©≥Á¥∞„ÅØ„Åì„Å°„Çâ„ÅÆ„Éò„É´„Éó„Çí„ÅîÂèÇÁÖß„Åè„Å†„Åï„ÅÑ‚áí',\n",
       " '329956',\n",
       " 'handles',\n",
       " '1205',\n",
       " 'routed',\n",
       " 'kaitlyn',\n",
       " 'https://t.co/pwvkqvrcl1',\n",
       " 'lt1',\n",
       " 'lunges',\n",
       " '461453',\n",
       " '702246',\n",
       " 'herb',\n",
       " 'https://t.co/vlvfjr4nn9?',\n",
       " '269039',\n",
       " 'mom‚Äôs',\n",
       " 'plaisir',\n",
       " 'landing',\n",
       " 'https://t.co/oqv2iggsom',\n",
       " 'verwendest',\n",
       " 'marian',\n",
       " 'tmobiled',\n",
       " 'valider',\n",
       " 'https://t.co/phfpti01sz',\n",
       " 'inappropriately',\n",
       " '245673',\n",
       " '531308',\n",
       " '151343',\n",
       " 'https://t.co/hbz0jtovd7',\n",
       " 'https://t.co/0es97nbnoj',\n",
       " 'westbury',\n",
       " '545043',\n",
       " '366438',\n",
       " 'connects',\n",
       " 'https://t.co/d9gao141km',\n",
       " 'https://t.co/neyezkph2b',\n",
       " '573852',\n",
       " 'holatengo',\n",
       " '312941',\n",
       " 'tbs',\n",
       " '‡§ï‡§ø‡§Ø‡§æ',\n",
       " 'endorse',\n",
       " 'brasil',\n",
       " '150mbps',\n",
       " '158538',\n",
       " 'liegt',\n",
       " 'update‚Ä¶',\n",
       " '335086',\n",
       " 'lvl',\n",
       " 'samuel',\n",
       " 'reversion',\n",
       " 'bcw',\n",
       " 'leading',\n",
       " 'glitchers',\n",
       " '35448',\n",
       " 'https://t.co/44xgzyayi1',\n",
       " '26773',\n",
       " 'addressmore',\n",
       " 'nak',\n",
       " 'hahahah',\n",
       " 'https://t.co/gnfwt1b0f4',\n",
       " 'youuuuuu',\n",
       " '471448',\n",
       " 'ks',\n",
       " '161500',\n",
       " '734151',\n",
       " 'wifimobile',\n",
       " '418543',\n",
       " 'hug',\n",
       " 'positivevibes',\n",
       " '289270',\n",
       " '01122017',\n",
       " 'overdraft',\n",
       " 'bruno',\n",
       " 'datamo',\n",
       " '204040',\n",
       " '311738',\n",
       " 'https://t.co/c4aneymmua',\n",
       " '27th',\n",
       " 'contesta',\n",
       " '360333',\n",
       " 'venido',\n",
       " 'recevoir',\n",
       " '821',\n",
       " 'copyright',\n",
       " '130621',\n",
       " '240727',\n",
       " '122168',\n",
       " 'attorney',\n",
       " '153919',\n",
       " '‚úîÔ∏è',\n",
       " 'https://t.co/emy8ww9u8c',\n",
       " 'mymathlab',\n",
       " 'https://t.co/5resfjxmpm',\n",
       " 'chipotleburrito',\n",
       " 'durchsuchbar',\n",
       " 'ek',\n",
       " '663826',\n",
       " '81408',\n",
       " 'https://t.co/m57zv8inei',\n",
       " 'https://t.co/8oqozlilsk',\n",
       " '‡§Ö‡§¨',\n",
       " '‚Äî',\n",
       " 'üè°',\n",
       " '474089',\n",
       " 'https://t.co/mjlkjz5lv1',\n",
       " 'mel',\n",
       " '661890',\n",
       " 'sorrys',\n",
       " '¬£1k',\n",
       " 'ww855q',\n",
       " 'pauses',\n",
       " '142289',\n",
       " 'https://t.co/tk4yevtand,',\n",
       " 'withdrawal',\n",
       " '423264',\n",
       " 'a26',\n",
       " 'sooooo',\n",
       " 'prebooked',\n",
       " 'wa',\n",
       " '195340',\n",
       " 'secretly',\n",
       " 'baltimore',\n",
       " 'andyd',\n",
       " '611445',\n",
       " 'aunt',\n",
       " '564075',\n",
       " 'docs',\n",
       " 'https://t.co/q4lamz3tbe',\n",
       " 'padnwp',\n",
       " '753511',\n",
       " 'livid',\n",
       " 'https://t.co/7xrdklljz1',\n",
       " 'kundenservice',\n",
       " 'flickers',\n",
       " 'transportals',\n",
       " '123900',\n",
       " 'scenic',\n",
       " 'waking',\n",
       " 'iah',\n",
       " '‚Äòcustomers',\n",
       " 'canceling',\n",
       " 'named',\n",
       " 'spaces',\n",
       " 'https://t.co/wbx3qatk76',\n",
       " '599275',\n",
       " '199303',\n",
       " 'https://t.co/pkasl0fbrb',\n",
       " '387324',\n",
       " 'border',\n",
       " '507954',\n",
       " 'muffin',\n",
       " 'acknowledged',\n",
       " 'pile',\n",
       " 'telco',\n",
       " 'cubs',\n",
       " '153945',\n",
       " 'https://t.co/c5aw5ftpuk',\n",
       " 'ces',\n",
       " 'abandonando',\n",
       " 'üêª',\n",
       " 'greenwich',\n",
       " 'https://t.co/4zxnylvq4o',\n",
       " '132522',\n",
       " 'pronto',\n",
       " 'riders',\n",
       " '153434',\n",
       " 'peoples',\n",
       " 'remains',\n",
       " '324701',\n",
       " '132555',\n",
       " '5281',\n",
       " 'finding',\n",
       " 'zugeordnet',\n",
       " '512565',\n",
       " 'purrfect',\n",
       " 'https://t.co/zcneqkuzvh.',\n",
       " '491809',\n",
       " 'üò°üî•üò°üî•',\n",
       " '693498',\n",
       " 'daughters',\n",
       " '‚Äúare',\n",
       " '775327',\n",
       " '748383',\n",
       " '460018',\n",
       " 'keepviacom',\n",
       " '‰∏ÅÂ∫¶„Éè„É≠„Ç¶„Ç£„É≥Ââç„ÅÆ„Ç¶„Ç£„ÉÉ„Ç∞Ë≥ºÂÖ•„Å†„Å£„Åü„Åã„Çâ„Åãamazon„Åï„Çì„Å´ÁõõÂ§ß„Å´ÂãòÈÅï„ÅÑ„Åï„Çå„Å¶„ÅÑ„Çã„ÄÇÈÅï„ÅÜ„Çà„ÄÅÁßÅ„ÅØ„Åü„Å†„Ç¶„Ç£„ÉÉ„Ç∞„ÅåÊ¨≤„Åó„Åã„Å£„Åü„Å†„Åë„Å™„ÅÆ„Çà„ÄÇ„Å†„Åã„Çâ„Éè„É≠„Ç¶„Ç£„É≥„Ç∞„ÉÉ„Ç∫„Ç™„Çπ„Çπ„É°„Åó„Å™„Åè„Å¶„ÅÑ„ÅÑ„Åß„Åô',\n",
       " 'https://t.co/l1fpadvktg',\n",
       " 'deliveries',\n",
       " 'üòê',\n",
       " '181162',\n",
       " 'pets',\n",
       " 'https://t.co/bxrvfeixxq',\n",
       " '170222',\n",
       " 'hk',\n",
       " 'ahem',\n",
       " '288891',\n",
       " 'conference',\n",
       " 'paso',\n",
       " '378188',\n",
       " '805555',\n",
       " 'airporttried',\n",
       " 'succumb',\n",
       " 'expressing',\n",
       " 'owe',\n",
       " '808634',\n",
       " '134825',\n",
       " 'https://t.co/nr93otlzg7',\n",
       " '483376',\n",
       " '514360',\n",
       " 'terc√ºme',\n",
       " 'üôämuchas',\n",
       " '281442',\n",
       " 'allüòí',\n",
       " '11267',\n",
       " '1248',\n",
       " 'anderen',\n",
       " 'everytimeicome',\n",
       " '429305',\n",
       " 'meantimegc',\n",
       " '261924',\n",
       " '822592',\n",
       " 'smfh',\n",
       " '1320',\n",
       " '120884',\n",
       " 'isaac',\n",
       " 'juan',\n",
       " 'https://t.co/bsebg3seui',\n",
       " 'hightech',\n",
       " '710538',\n",
       " 'ÿ™ŸÖÿßŸÖÿå',\n",
       " 'wahala',\n",
       " '745118',\n",
       " 'viable',\n",
       " 'marting',\n",
       " '121017',\n",
       " '106245',\n",
       " 'rechnungsbetrag',\n",
       " 'curtly',\n",
       " 'vendor',\n",
       " '533690',\n",
       " 'shoved',\n",
       " 'accommodations',\n",
       " 'darshan',\n",
       " 'emoji',\n",
       " 'therelivechat',\n",
       " 'https://t.co/awwrmn54vu',\n",
       " 'mutual',\n",
       " 'pvt',\n",
       " 'https://t.co/ay5emegzci',\n",
       " 'steaks',\n",
       " 'yeezy',\n",
       " '240264',\n",
       " 'trr',\n",
       " '545098',\n",
       " '445424',\n",
       " 'bn',\n",
       " 'lien',\n",
       " 'departs',\n",
       " 'abn',\n",
       " '477377',\n",
       " '436037',\n",
       " '185308',\n",
       " 'shoreham',\n",
       " 'nostra',\n",
       " '531331',\n",
       " 'hotmail',\n",
       " 'shortcuts',\n",
       " 'holdcombe',\n",
       " 'mate',\n",
       " 'https://t.co/3h0tnpwp0c',\n",
       " 'otur',\n",
       " '494847',\n",
       " 'https://t.co/p0acrjxdkz',\n",
       " '562400',\n",
       " 'horizon',\n",
       " 'cheaper',\n",
       " '244230',\n",
       " 'celular',\n",
       " 'directl',\n",
       " '166988',\n",
       " 'larticle',\n",
       " 'swartzcreek',\n",
       " 'skystar',\n",
       " 'sped',\n",
       " '606800',\n",
       " 'https://t.co/gquaxlmc1e',\n",
       " '725739',\n",
       " '629775',\n",
       " 'goin',\n",
       " '323161',\n",
       " 'pr√ºfen',\n",
       " '50minute',\n",
       " 'precheck',\n",
       " 'gnaw',\n",
       " 'usernamepassword',\n",
       " '117347',\n",
       " 'mentally',\n",
       " 'noas',\n",
       " '251095',\n",
       " 'cob',\n",
       " '‚Äòdelayed‚Äô',\n",
       " '¬£27930',\n",
       " 'crowded',\n",
       " 'üôÑü§∑üèª\\u200d‚ôÇÔ∏è',\n",
       " '362676',\n",
       " '714909',\n",
       " 'lalit',\n",
       " '234291',\n",
       " 'brother‚Äôs',\n",
       " 'concern√©',\n",
       " '653175',\n",
       " '432907',\n",
       " 'https://t.co/b5ddj3sgj6',\n",
       " 'usereach',\n",
       " '634977',\n",
       " 'angry',\n",
       " 'gina',\n",
       " 'helpplease',\n",
       " 'ŸÅŸä',\n",
       " '63303',\n",
       " '230565',\n",
       " '154982',\n",
       " 'push',\n",
       " '402128',\n",
       " 'bexhill',\n",
       " 'ÿßŸÑŸÜÿ∏ÿßŸÖ',\n",
       " '139553',\n",
       " '53',\n",
       " 'lamento',\n",
       " 'tax',\n",
       " '145819',\n",
       " 'bravo',\n",
       " '362127',\n",
       " '379476',\n",
       " '106695',\n",
       " 'inferior',\n",
       " 'contactorder',\n",
       " '136236',\n",
       " 'deadline',\n",
       " '2g3g',\n",
       " 'üòãüòãüòã',\n",
       " '0501',\n",
       " 'router‚Äôs',\n",
       " 'teasing',\n",
       " '145995',\n",
       " 'ottomans',\n",
       " 'https://t.co/riaaxvaevz',\n",
       " 'https://t.co/rs5khddwdo',\n",
       " '527944',\n",
       " 'https://t.co/kfz9790icw',\n",
       " 'acrobat',\n",
       " 'doy',\n",
       " 'sna',\n",
       " 'https://t.co/qysthl7bmr',\n",
       " '427480',\n",
       " 'wolfgang',\n",
       " '453766',\n",
       " 'guactober',\n",
       " '810254',\n",
       " '17112017',\n",
       " ...}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_words(text):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for w in text.split():\n",
    "        if w.lower() not in rare_words or w.lower().startswith('http'):\n",
    "            res.append(w)\n",
    "            \n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(remove_rare_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whats egg website people talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ios11 applesupport https://t.co/bxrvfeixxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assist recommend updating ios 1111 havent chance also following link support https://t.co/gdrqu22ypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115955 thats better connection drops every mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica probably one best airlines ive ever experienced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   text\n",
       "0                                                                         whats egg website people talk\n",
       "1                                                            ios11 applesupport https://t.co/bxrvfeixxq\n",
       "2  assist recommend updating ios 1111 havent chance also following link support https://t.co/gdrqu22ypt\n",
       "3                                                       115955 thats better connection drops every mins\n",
       "4                                         virginamerica probably one best airlines ive ever experienced"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form (From Wikipedia)\n",
    "\n",
    "For example, if there are two words in the corpus walks and walking, then stemming will stem the suffix to make them walk. But say in another example, we have two words console and consoling, the stemmer will remove the suffix and make them consol which is not a proper english word.\n",
    "\n",
    "There are several type of stemming algorithms available and one of the famous one is porter stemmer which is widely used. We can use nltk package for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'danc'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"dancing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for w in text.split():\n",
    "        res.append(ps.stem(w))\n",
    "        \n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what egg websit peopl talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ios11 applesupport https://t.co/bxrvfeixxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assist recommend updat io 1111 havent chanc also follow link support https://t.co/gdrqu22ypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115955 that better connect drop everi min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica probabl one best airlin ive ever experienc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text\n",
       "0                                                                    what egg websit peopl talk\n",
       "1                                                    ios11 applesupport https://t.co/bxrvfeixxq\n",
       "2  assist recommend updat io 1111 havent chanc also follow link support https://t.co/gdrqu22ypt\n",
       "3                                                     115955 that better connect drop everi min\n",
       "4                                      virginamerica probabl one best airlin ive ever experienc"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "Lemmatization is similar to stemming in reducing inflected words to their word stem but differs in the way that it makes sure the root word (also called as lemma) belongs to the language.\n",
    "\n",
    "As a result, this one is generally slower than stemming process. So depending on the speed requirement, we can choose to use either stemming or lemmatization.\n",
    "\n",
    "Let us use the WordNetLemmatizer in nltk to lemmatize our sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/praveen/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dance'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize(\"dancing\", pos='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo the lemmatization process with POS tag for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/praveen/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('dancing', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('my', 'PRP$'),\n",
       " ('heart', 'NN')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(\"I am dancing to my heart\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Emojis\n",
    "\n",
    "With more and more usage of social media platforms, there is an explosion in the usage of emojis in our day to day life as well. Probably we might need to remove these emojis for some of our textual analysis.\n",
    "\n",
    "Thanks to [this code](https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b), please find below a helper function to remove emojis from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game is on '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "remove_emoji(\"game is on üî•üî•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what egg websit peopl talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ios11 applesupport https://t.co/bxrvfeixxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assist recommend updat io 1111 havent chanc also follow link support https://t.co/gdrqu22ypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115955 that better connect drop everi min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica probabl one best airlin ive ever experienc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           text\n",
       "0                                                                    what egg websit peopl talk\n",
       "1                                                    ios11 applesupport https://t.co/bxrvfeixxq\n",
       "2  assist recommend updat io 1111 havent chanc also follow link support https://t.co/gdrqu22ypt\n",
       "3                                                     115955 that better connect drop everi min\n",
       "4                                      virginamerica probabl one best airlin ive ever experienc"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of URLs\n",
    "\n",
    "Next preprocessing step is to remove any URLs present in the data. For example, if we are doing a twitter analysis, then there is a good chance that the tweet will have some URL in it. Probably we might need to remove them for our further analysis.\n",
    "\n",
    "We can use the below code snippet to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+|t\\.co\\S+')\n",
    "    return url_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what egg websit peopl talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ios11 applesupport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assist recommend updat io 1111 havent chanc also follow link support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115955 that better connect drop everi min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica probabl one best airlin ive ever experienc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    text\n",
       "0                                             what egg websit peopl talk\n",
       "1                                                    ios11 applesupport \n",
       "2  assist recommend updat io 1111 havent chanc also follow link support \n",
       "3                              115955 that better connect drop everi min\n",
       "4               virginamerica probabl one best airlin ive ever experienc"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
